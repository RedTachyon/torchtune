{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T23:10:36.599714Z",
     "start_time": "2025-01-26T23:10:34.844895Z"
    }
   },
   "source": [
    "import torchtune\n",
    "import os, sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from recipes.r1_full_single_device import FullRLRecipeSingleDevice\n",
    "from omegaconf import OmegaConf"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:10:37.427962Z",
     "start_time": "2025-01-26T23:10:37.418968Z"
    }
   },
   "cell_type": "code",
   "source": "cfg = OmegaConf.load(\"../recipes/configs/llama3_2/3B_full_rl_single_device.yaml\")",
   "id": "353d79babd3c36b3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:10:38.594656Z",
     "start_time": "2025-01-26T23:10:38.571108Z"
    }
   },
   "cell_type": "code",
   "source": "recipe = FullRLRecipeSingleDevice(cfg)",
   "id": "8bac7f2c5ce7c035",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 1998871262. Local seed is seed + rank = 1998871262 + 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:10:47.060109Z",
     "start_time": "2025-01-26T23:10:40.395971Z"
    }
   },
   "cell_type": "code",
   "source": "recipe.setup(cfg=cfg)",
   "id": "be5383142edc90b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing logs to /Users/ariel/checkpoint/tmp/full-llama3.2-finetune/log_1737933040.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils._logging:Model is initialized with precision torch.bfloat16.\n",
      "INFO:torchtune.utils._logging:Tokenizer is initialized from file.\n",
      "/Users/ariel/projects/torchtune-rl/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "INFO:torchtune.utils._logging:In-backward optimizers are set up.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils._logging:Dataset and Sampler are initialized.\n",
      "INFO:torchtune.utils._logging:No learning rate scheduler configured. Using constant learning rate.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:10:47.704740Z",
     "start_time": "2025-01-26T23:10:47.694205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, batch in enumerate(recipe._dataloader):\n",
    "    print(i)\n",
    "    print(batch)\n",
    "    break"
   ],
   "id": "e674970d809e5faa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'tokens': tensor([[128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,  55357,   6944,    311,   3780,\n",
      "            264,  13339,   4447,    430,   7194,    220,     17,  28518,   2734,\n",
      "          14801,     13,  55357,    706,    220,   4370,   3117,  58174,     11,\n",
      "            323,   1070,    527,    220,     21,   3117,  58174,    311,    264,\n",
      "          28518,   2734,    343,     13,   2650,   1690,  28518,   2734,  14801,\n",
      "            690,  55357,    617,   2163,   1306,  12096,    279,   4447,   4710,\n",
      "          22103,     25, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004],\n",
      "        [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,    362,  18172,  41327,    538,\n",
      "           4024,    389,    264,   2115,   8577,    311,    279,  42014,     11,\n",
      "            323,    872,    538,    315,    220,    605,   4236,  27092,    449,\n",
      "           2500,    538,    449,    279,   1890,   3392,    315,   4236,     13,\n",
      "            220,     20,   6699,   9076,    311,    387,    264,    523,   3271,\n",
      "            606,     11,    323,    220,     17,    315,    279,  13639,    505,\n",
      "           2225,   6989,    690,    387,   1070,   2288,     13,   3277,    279,\n",
      "           2978,   1938,    574,    927,     11,    279,   4236,   1436,   5268,\n",
      "            311,    733,   2162,    323,    220,    605,    315,   1124,   2163,\n",
      "             13,   9220,    315,    279,    523,   3271,   3233,   1051,   6699,\n",
      "            304,    430,   1912,     11,    779,    814,   2163,    439,   1664,\n",
      "             13,   2650,   1690,   7931,   1051,   2163,    520,    279,  42014,\n",
      "           4710,  22103,     25],\n",
      "        [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,  15383,    596,  11326,  12893,\n",
      "            220,     16,   6596,    315,   5403,   2391,    279,   9178,     13,\n",
      "           1952,   6740,   3814,     11,  15383,   1373,    369,    220,    845,\n",
      "           4520,     13,   1952,   7884,   1364,   1373,    369,    220,   1591,\n",
      "           4520,     13,   2650,   1690,   4520,   1587,  15383,    617,    311,\n",
      "           1373,    389,   7418,    311,   4686,    279,  16720,   4710,  22103,\n",
      "             25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004],\n",
      "        [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,    578,  31230,    315,    264,\n",
      "           5410,  19794,  79771,    374,    220,    605,   7693,   3485,    279,\n",
      "           5015,     13,    220,  23212,     11,   1455,  11909,    690,   2019,\n",
      "            430,    264,   2851,   2011,    387,   3025,    311,   5662,    520,\n",
      "           3325,    220,     21,  15271,   3485,    279,  31230,    311,  64572,\n",
      "            264,  19794,     13,    220,  83710,    264,  19794,   2851,    374,\n",
      "            220,     21,   7693,  16615,    323,    649,   5662,    220,   1313,\n",
      "          15271,   3485,    872,   2010,   1701,    279,  27296,    857,    315,\n",
      "            872,  11977,     13,    220,   2650,   1579,   2011,    420,   2851,\n",
      "            387,   3025,    311,   7940,    311,   5662,    220,     21,  15271,\n",
      "           3485,    279,  31230,    311,  64572,    264,  19794,   4710,  22103,\n",
      "             25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004]]), 'answers': ['7', '15', '16', '32']}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:10:53.924748Z",
     "start_time": "2025-01-26T23:10:53.915466Z"
    }
   },
   "cell_type": "code",
   "source": "tokens = batch[\"tokens\"].to(\"mps\")",
   "id": "38a61fede34f5ee",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:11:59.638646Z",
     "start_time": "2025-01-26T23:10:56.065787Z"
    }
   },
   "cell_type": "code",
   "source": "out_tokens, out_logits = recipe.generate_trajectory(tokens)",
   "id": "91a2fca58d2b64ff",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:12:07.827356Z",
     "start_time": "2025-01-26T23:12:07.822630Z"
    }
   },
   "cell_type": "code",
   "source": "batch[\"answers\"]",
   "id": "780c9aea1f946642",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '15', '16', '32']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:12:09.878963Z",
     "start_time": "2025-01-26T23:12:09.875571Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.encode(\"</answer>\", False, False)",
   "id": "9027fcd15616ff51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[524, 9399, 29]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:32:57.502986Z",
     "start_time": "2025-01-26T23:32:57.500454Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.encode(\"Something<|finetune_right_pad_id|>blah\", True, True)",
   "id": "6eda927c63b8a795",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000,\n",
       " 23958,\n",
       " 27,\n",
       " 91,\n",
       " 5589,\n",
       " 295,\n",
       " 2957,\n",
       " 10762,\n",
       " 31390,\n",
       " 851,\n",
       " 91,\n",
       " 29,\n",
       " 71714,\n",
       " 128001]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:34:07.624985Z",
     "start_time": "2025-01-26T23:34:07.619989Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._model.tok_emb",
   "id": "935b4c7b67745c43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoder(\n",
       "  (tok_embeddings): Embedding(128256, 3072)\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x CheckpointWrapper(\n",
       "      (_checkpoint_wrapped_module): TransformerSelfAttentionLayer(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (output_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (pos_embeddings): Llama3ScaledRoPE()\n",
       "        )\n",
       "        (mlp): FeedForward(\n",
       "          (w1): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (w2): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (w3): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (activation): SiLU()\n",
       "        )\n",
       "        (sa_norm): RMSNorm()\n",
       "        (mlp_norm): RMSNorm()\n",
       "        (sa_scale): Identity()\n",
       "        (mlp_scale): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:23:03.762721Z",
     "start_time": "2025-01-26T23:23:03.754797Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode(out_tokens[0].tolist(), False, False)",
   "id": "ad10201b2a5aece1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think></think> and <answer></answer> tags, respectively, i.e., <think>reasoning process here</think> <answer>answer here</answer>. User: Gerald wants to buy a meat pie that costs 2 pfennigs. Gerald has 54 farthings, and there are 6 farthings to a pfennig. How many pfennigs will Gerald have left after buying the pie?. Assistant:<|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|>. <think>Count 54 farthings. Divide by 6. This is the number of pfennigs in 54 farthings. Multiply 54 farthings by 2 to get the cost. Subtract the cost from 54 to get the number of pfennigs left. </think> . <answer>27 pfennigs</answer>\\nAssistant: Gerald wants to buy a meat pie that costs 2 pfennigs. Gerald has 54 farthings, and there are '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:24:34.416781Z",
     "start_time": "2025-01-26T23:24:34.405489Z"
    }
   },
   "cell_type": "code",
   "source": "out_tokens[0][150]",
   "id": "9f61a664f5194397",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128004, device='mps:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:24:49.043516Z",
     "start_time": "2025-01-26T23:24:48.997191Z"
    }
   },
   "cell_type": "code",
   "source": "out_logits[0, 152].argmax()",
   "id": "a4a6fda38ee60c7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, device='mps:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:18:11.894985Z",
     "start_time": "2025-01-26T23:18:11.889736Z"
    }
   },
   "cell_type": "code",
   "source": "batch",
   "id": "f8b1c8ae1ff14817",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,  55357,   6944,    311,   3780,\n",
       "             264,  13339,   4447,    430,   7194,    220,     17,  28518,   2734,\n",
       "           14801,     13,  55357,    706,    220,   4370,   3117,  58174,     11,\n",
       "             323,   1070,    527,    220,     21,   3117,  58174,    311,    264,\n",
       "           28518,   2734,    343,     13,   2650,   1690,  28518,   2734,  14801,\n",
       "             690,  55357,    617,   2163,   1306,  12096,    279,   4447,   4710,\n",
       "           22103,     25, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004],\n",
       "         [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,    362,  18172,  41327,    538,\n",
       "            4024,    389,    264,   2115,   8577,    311,    279,  42014,     11,\n",
       "             323,    872,    538,    315,    220,    605,   4236,  27092,    449,\n",
       "            2500,    538,    449,    279,   1890,   3392,    315,   4236,     13,\n",
       "             220,     20,   6699,   9076,    311,    387,    264,    523,   3271,\n",
       "             606,     11,    323,    220,     17,    315,    279,  13639,    505,\n",
       "            2225,   6989,    690,    387,   1070,   2288,     13,   3277,    279,\n",
       "            2978,   1938,    574,    927,     11,    279,   4236,   1436,   5268,\n",
       "             311,    733,   2162,    323,    220,    605,    315,   1124,   2163,\n",
       "              13,   9220,    315,    279,    523,   3271,   3233,   1051,   6699,\n",
       "             304,    430,   1912,     11,    779,    814,   2163,    439,   1664,\n",
       "              13,   2650,   1690,   7931,   1051,   2163,    520,    279,  42014,\n",
       "            4710,  22103,     25],\n",
       "         [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,  15383,    596,  11326,  12893,\n",
       "             220,     16,   6596,    315,   5403,   2391,    279,   9178,     13,\n",
       "            1952,   6740,   3814,     11,  15383,   1373,    369,    220,    845,\n",
       "            4520,     13,   1952,   7884,   1364,   1373,    369,    220,   1591,\n",
       "            4520,     13,   2650,   1690,   4520,   1587,  15383,    617,    311,\n",
       "            1373,    389,   7418,    311,   4686,    279,  16720,   4710,  22103,\n",
       "              25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004],\n",
       "         [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,    578,  31230,    315,    264,\n",
       "            5410,  19794,  79771,    374,    220,    605,   7693,   3485,    279,\n",
       "            5015,     13,    220,  23212,     11,   1455,  11909,    690,   2019,\n",
       "             430,    264,   2851,   2011,    387,   3025,    311,   5662,    520,\n",
       "            3325,    220,     21,  15271,   3485,    279,  31230,    311,  64572,\n",
       "             264,  19794,     13,    220,  83710,    264,  19794,   2851,    374,\n",
       "             220,     21,   7693,  16615,    323,    649,   5662,    220,   1313,\n",
       "           15271,   3485,    872,   2010,   1701,    279,  27296,    857,    315,\n",
       "             872,  11977,     13,    220,   2650,   1579,   2011,    420,   2851,\n",
       "             387,   3025,    311,   7940,    311,   5662,    220,     21,  15271,\n",
       "            3485,    279,  31230,    311,  64572,    264,  19794,   4710,  22103,\n",
       "              25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004]]),\n",
       " 'answers': ['7', '15', '16', '32']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Next TODO:\n",
    "- [ ] Properly format the prompt in the data\n",
    "- [ ] Do the RL training loop"
   ],
   "id": "872551481417c09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "RESEARCH IDEA:\n",
    "Continuous RL for CoT? instead of predicting tokens, we predict the continuous embeddings"
   ],
   "id": "46fa9d9db0976173"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
