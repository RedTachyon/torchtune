{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:53:26.601471Z",
     "start_time": "2025-01-28T14:53:26.597370Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "6a0e1030eeb96319",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T16:09:49.337722Z",
     "start_time": "2025-01-28T16:09:49.334842Z"
    }
   },
   "cell_type": "code",
   "source": "rewards = torch.rand(4, 5, dtype=torch.float16)",
   "id": "393ecf66b8f9cd13",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:54:34.463127Z",
     "start_time": "2025-01-28T14:54:34.458240Z"
    }
   },
   "cell_type": "code",
   "source": "rewards - rewards.mean(1, keepdim=True) / rewards.std(1, keepdim=True)",
   "id": "7ebb720d82079954",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4924, -1.1812, -0.9333, -1.3558, -0.4794],\n",
       "        [-0.7612, -0.7557, -0.9516, -0.2712, -0.9327],\n",
       "        [-1.8456, -1.2907, -1.8423, -1.2641, -1.4576],\n",
       "        [-0.8187, -0.6733, -0.8718, -1.2719, -1.1838]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T21:17:04.191917Z",
     "start_time": "2025-01-27T21:16:57.380370Z"
    }
   },
   "source": [
    "import torchtune\n",
    "import os, sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from recipes.r1_full_single_device import FullRLRecipeSingleDevice\n",
    "from omegaconf import OmegaConf"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:17:04.209898Z",
     "start_time": "2025-01-27T21:17:04.197726Z"
    }
   },
   "cell_type": "code",
   "source": "cfg = OmegaConf.load(\"../recipes/configs/llama3_2/3B_full_rl_single_device_cuda.yaml\")",
   "id": "353d79babd3c36b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:17:53.453669Z",
     "start_time": "2025-01-27T21:17:53.073191Z"
    }
   },
   "cell_type": "code",
   "source": "recipe = FullRLRecipeSingleDevice(cfg)",
   "id": "8bac7f2c5ce7c035",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 3763484870. Local seed is seed + rank = 3763484870 + 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:18:03.354484Z",
     "start_time": "2025-01-27T21:17:57.505271Z"
    }
   },
   "cell_type": "code",
   "source": "recipe.setup(cfg=cfg)",
   "id": "be5383142edc90b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing logs to /checkpoint/kwiat/tmp/full-llama3.2-finetune/log_1738012677.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils._logging:Model is initialized with precision torch.bfloat16.\n",
      "INFO:torchtune.utils._logging:Memory stats after model init:\n",
      "\tGPU peak memory allocation: 12.09 GiB\n",
      "\tGPU peak memory reserved: 12.19 GiB\n",
      "\tGPU peak memory active: 12.09 GiB\n",
      "INFO:torchtune.utils._logging:Tokenizer is initialized from file.\n",
      "INFO:torchtune.utils._logging:In-backward optimizers are set up.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n",
      "INFO:torchtune.utils._logging:Dataset and Sampler are initialized.\n",
      "INFO:torchtune.utils._logging:No learning rate scheduler configured. Using constant learning rate.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:19:33.651367Z",
     "start_time": "2025-01-27T21:19:33.634612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, batch in enumerate(recipe._dataloader):\n",
    "    print(i)\n",
    "    print(batch)\n",
    "    break"
   ],
   "id": "e674970d809e5faa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'tokens': tensor([[128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,  55357,   6944,    311,   3780,\n",
      "            264,  13339,   4447,    430,   7194,    220,     17,  28518,   2734,\n",
      "          14801,     13,  55357,    706,    220,   4370,   3117,  58174,     11,\n",
      "            323,   1070,    527,    220,     21,   3117,  58174,    311,    264,\n",
      "          28518,   2734,    343,     13,   2650,   1690,  28518,   2734,  14801,\n",
      "            690,  55357,    617,   2163,   1306,  12096,    279,   4447,   4710,\n",
      "          22103,     25, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004],\n",
      "        [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,    362,  18172,  41327,    538,\n",
      "           4024,    389,    264,   2115,   8577,    311,    279,  42014,     11,\n",
      "            323,    872,    538,    315,    220,    605,   4236,  27092,    449,\n",
      "           2500,    538,    449,    279,   1890,   3392,    315,   4236,     13,\n",
      "            220,     20,   6699,   9076,    311,    387,    264,    523,   3271,\n",
      "            606,     11,    323,    220,     17,    315,    279,  13639,    505,\n",
      "           2225,   6989,    690,    387,   1070,   2288,     13,   3277,    279,\n",
      "           2978,   1938,    574,    927,     11,    279,   4236,   1436,   5268,\n",
      "            311,    733,   2162,    323,    220,    605,    315,   1124,   2163,\n",
      "             13,   9220,    315,    279,    523,   3271,   3233,   1051,   6699,\n",
      "            304,    430,   1912,     11,    779,    814,   2163,    439,   1664,\n",
      "             13,   2650,   1690,   7931,   1051,   2163,    520,    279,  42014,\n",
      "           4710,  22103,     25],\n",
      "        [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,  15383,    596,  11326,  12893,\n",
      "            220,     16,   6596,    315,   5403,   2391,    279,   9178,     13,\n",
      "           1952,   6740,   3814,     11,  15383,   1373,    369,    220,    845,\n",
      "           4520,     13,   1952,   7884,   1364,   1373,    369,    220,   1591,\n",
      "           4520,     13,   2650,   1690,   4520,   1587,  15383,    617,    311,\n",
      "           1373,    389,   7418,    311,   4686,    279,  16720,   4710,  22103,\n",
      "             25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004],\n",
      "        [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
      "           1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
      "            433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
      "           1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
      "            449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
      "            527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
      "            366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
      "            602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
      "           1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
      "            524,   9399,  14611,   2724,     25,    578,  31230,    315,    264,\n",
      "           5410,  19794,  79771,    374,    220,    605,   7693,   3485,    279,\n",
      "           5015,     13,    220,  23212,     11,   1455,  11909,    690,   2019,\n",
      "            430,    264,   2851,   2011,    387,   3025,    311,   5662,    520,\n",
      "           3325,    220,     21,  15271,   3485,    279,  31230,    311,  64572,\n",
      "            264,  19794,     13,    220,  83710,    264,  19794,   2851,    374,\n",
      "            220,     21,   7693,  16615,    323,    649,   5662,    220,   1313,\n",
      "          15271,   3485,    872,   2010,   1701,    279,  27296,    857,    315,\n",
      "            872,  11977,     13,    220,   2650,   1579,   2011,    420,   2851,\n",
      "            387,   3025,    311,   7940,    311,   5662,    220,     21,  15271,\n",
      "           3485,    279,  31230,    311,  64572,    264,  19794,   4710,  22103,\n",
      "             25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
      "         128004, 128004, 128004]]), 'answers': ['7', '15', '16', '32']}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:19:41.164961Z",
     "start_time": "2025-01-27T21:19:41.161350Z"
    }
   },
   "cell_type": "code",
   "source": "tokens = batch[\"tokens\"].to(\"cuda\")",
   "id": "38a61fede34f5ee",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:21:48.337877Z",
     "start_time": "2025-01-27T21:21:48.335090Z"
    }
   },
   "cell_type": "code",
   "source": "batch_tokens = tokens[:, None, :].expand(-1, 3, -1)",
   "id": "4e452c04854667dd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:21:49.471194Z",
     "start_time": "2025-01-27T21:21:49.467520Z"
    }
   },
   "cell_type": "code",
   "source": "batch_tokens.shape",
   "id": "ebf3ba57e184df89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:24:40.606299Z",
     "start_time": "2025-01-27T21:24:40.600375Z"
    }
   },
   "cell_type": "code",
   "source": "batch_tokens.reshape(4*3, 192)",
   "id": "a1c14284e35a7d0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,     32,  10652,  ..., 128004, 128004, 128004],\n",
       "        [128000,     32,  10652,  ..., 128004, 128004, 128004],\n",
       "        [128000,     32,  10652,  ..., 128004, 128004, 128004],\n",
       "        ...,\n",
       "        [128000,     32,  10652,  ..., 128004, 128004, 128004],\n",
       "        [128000,     32,  10652,  ..., 128004, 128004, 128004],\n",
       "        [128000,     32,  10652,  ..., 128004, 128004, 128004]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:28:00.448861Z",
     "start_time": "2025-01-27T21:24:48.733487Z"
    }
   },
   "cell_type": "code",
   "source": "query_responses, logits = recipe.generate_trajectory(batch_tokens.reshape(4*3, -1))",
   "id": "91a2fca58d2b64ff",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:30:41.056285Z",
     "start_time": "2025-01-27T21:30:41.053330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_responses = query_responses.reshape(4, 3, -1)\n",
    "logits = logits.reshape(4, 3, -1)"
   ],
   "id": "ba619453f700bdd7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:31:13.156435Z",
     "start_time": "2025-01-27T21:31:13.153447Z"
    }
   },
   "cell_type": "code",
   "source": "c1, c2, c3 = query_responses[0].tolist()",
   "id": "f8207bbb3840ec1e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T23:14:19.861470Z",
     "start_time": "2025-01-27T23:14:19.857633Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.encode(\"Hello, world!\")",
   "id": "aabe26a280187f14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 9906, 11, 1917, 0, 128001]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T23:14:39.290996Z",
     "start_time": "2025-01-27T23:14:39.286804Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode([0], False, False)",
   "id": "97756a06f258202c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T23:21:28.233885Z",
     "start_time": "2025-01-27T23:21:28.230037Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode(recipe._tokenizer.stop_tokens, False, False)",
   "id": "8072e5c6db50f88a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|end_of_text|><|eot_id|><|eom_id|>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:56:36.919929Z",
     "start_time": "2025-01-27T21:56:36.915707Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode(c2, False, False)",
   "id": "e6eac70b6b87cf7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think></think> and <answer></answer> tags, respectively, i.e., <think>reasoning process here</think> <answer>answer here</answer>. User: Gerald wants to buy a meat pie that costs 2 pfennigs. Gerald has 54 farthings, and there are 6 farthings to a pfennig. How many pfennigs will Gerald have left after buying the pie?. Assistant:<|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|>| <think> To find how many pfennigs Gerald will have left, we think about the reasoning process. Let x be the number of pfennigs that Gerald will have left. Then we can write a number sentence for Gerald's money problem. The number sentence is Gerald has 54 farthings, and there are 6 farthings to a pfennig, so Gerald has 54 farthings x pfennigs. We can rewrite this as 6x=54, because there\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:51:43.025122Z",
     "start_time": "2025-01-27T14:51:43.022015Z"
    }
   },
   "cell_type": "code",
   "source": "batch_size, context_length = tokens.shape",
   "id": "f30b176296fad4e3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:52:01.861063Z",
     "start_time": "2025-01-27T14:52:01.857832Z"
    }
   },
   "cell_type": "code",
   "source": "responses = query_responses[:, context_length:].clone()",
   "id": "79af27bae0eda538",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:53:31.756824Z",
     "start_time": "2025-01-27T14:53:31.750145Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode(batch[\"tokens\"][1].tolist())",
   "id": "eec3b6d8f3af67cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think></think> and <answer></answer> tags, respectively, i.e., <think>reasoning process here</think> <answer>answer here</answer>. User: A fifth-grade class went on a field trip to the zoo, and their class of 10 students merged with another class with the same amount of students. 5 parents offered to be a chaperone, and 2 of the teachers from both classes will be there too. When the school day was over, the students could choose to go home and 10 of them left. Two of the chaperones were parents in that group, so they left as well. How many individuals were left at the zoo?. Assistant:'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:56:53.734972Z",
     "start_time": "2025-01-27T14:56:53.730943Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode(responses[1].tolist())",
   "id": "4befc2f1a7e163d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <think>First, I have to find out how many people left the zoo. That was 10 + 2 - 10 - 2 = 0.</think> <answer>There were 0 individuals left at the zoo.</answer><|end_of_text|><|begin_of_text|>The number of individuals left at the zoo is 0. 5<|end_of_text|><|begin_of_text|>This is because 10 parents offered to be a chaperone, and 2 of the teachers from both classes will be there too. Two of the'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:58:07.786719Z",
     "start_time": "2025-01-27T14:58:07.783442Z"
    }
   },
   "cell_type": "code",
   "source": "query_response_padding_masks = (query_responses != recipe._tokenizer.pad_id)",
   "id": "3a17acf5c9616fa8",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:00:37.011926Z",
     "start_time": "2025-01-27T15:00:37.007924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchtune import generation\n",
    "\n",
    "masks = generation.get_causal_mask_from_padding_mask(query_response_padding_masks)"
   ],
   "id": "1fa6d55346e01c43",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:07:33.699103Z",
     "start_time": "2025-01-27T15:07:33.696091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "position_ids = generation.get_position_ids_from_padding_mask(\n",
    "            query_response_padding_masks\n",
    "        )"
   ],
   "id": "306199c1fd102ef8",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:08:57.071810Z",
     "start_time": "2025-01-27T15:08:57.068527Z"
    }
   },
   "cell_type": "code",
   "source": "logits = logits[:, context_length-1:]",
   "id": "193dadf8dbd6d6fe",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:09:29.680364Z",
     "start_time": "2025-01-27T15:09:29.673115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchtune import rlhf\n",
    "\n",
    "logprobs = rlhf.logits_to_logprobs(logits, responses, 1.0)"
   ],
   "id": "b64162abcd9a4ca8",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:10:29.924411Z",
     "start_time": "2025-01-27T15:10:29.918809Z"
    }
   },
   "cell_type": "code",
   "source": "logprobs.shape",
   "id": "f6f0635a5267c454",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:11:32.943368Z",
     "start_time": "2025-01-27T15:11:32.553786Z"
    }
   },
   "cell_type": "code",
   "source": "ref_logits = recipe._model(query_responses.clone(), input_pos=position_ids, mask=masks)",
   "id": "ee02db9dc032c550",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:14:14.105454Z",
     "start_time": "2025-01-27T15:14:14.101425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ref_logits = rlhf.truncate_sequence_for_logprobs(ref_logits, context_length)\n",
    "ref_logprobs = rlhf.logits_to_logprobs(ref_logits, responses, 1.0)"
   ],
   "id": "33903dddf9314f81",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T13:38:31.328532Z",
     "start_time": "2025-01-27T13:38:31.321455Z"
    }
   },
   "cell_type": "code",
   "source": "batch[\"answers\"]",
   "id": "780c9aea1f946642",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '15', '16', '32']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T13:38:42.917947Z",
     "start_time": "2025-01-27T13:38:42.907771Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._model.tok_embeddings",
   "id": "935b4c7b67745c43",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128256, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:23:03.762721Z",
     "start_time": "2025-01-26T23:23:03.754797Z"
    }
   },
   "cell_type": "code",
   "source": "recipe._tokenizer.decode(out_tokens[0].tolist(), False, False)",
   "id": "ad10201b2a5aece1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think></think> and <answer></answer> tags, respectively, i.e., <think>reasoning process here</think> <answer>answer here</answer>. User: Gerald wants to buy a meat pie that costs 2 pfennigs. Gerald has 54 farthings, and there are 6 farthings to a pfennig. How many pfennigs will Gerald have left after buying the pie?. Assistant:<|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|><|finetune_right_pad_id|>. <think>Count 54 farthings. Divide by 6. This is the number of pfennigs in 54 farthings. Multiply 54 farthings by 2 to get the cost. Subtract the cost from 54 to get the number of pfennigs left. </think> . <answer>27 pfennigs</answer>\\nAssistant: Gerald wants to buy a meat pie that costs 2 pfennigs. Gerald has 54 farthings, and there are '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:24:34.416781Z",
     "start_time": "2025-01-26T23:24:34.405489Z"
    }
   },
   "cell_type": "code",
   "source": "out_tokens[0][150]",
   "id": "9f61a664f5194397",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128004, device='mps:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:24:49.043516Z",
     "start_time": "2025-01-26T23:24:48.997191Z"
    }
   },
   "cell_type": "code",
   "source": "out_logits[0, 152].argmax()",
   "id": "a4a6fda38ee60c7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, device='mps:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T23:18:11.894985Z",
     "start_time": "2025-01-26T23:18:11.889736Z"
    }
   },
   "cell_type": "code",
   "source": "batch",
   "id": "f8b1c8ae1ff14817",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,  55357,   6944,    311,   3780,\n",
       "             264,  13339,   4447,    430,   7194,    220,     17,  28518,   2734,\n",
       "           14801,     13,  55357,    706,    220,   4370,   3117,  58174,     11,\n",
       "             323,   1070,    527,    220,     21,   3117,  58174,    311,    264,\n",
       "           28518,   2734,    343,     13,   2650,   1690,  28518,   2734,  14801,\n",
       "             690,  55357,    617,   2163,   1306,  12096,    279,   4447,   4710,\n",
       "           22103,     25, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004],\n",
       "         [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,    362,  18172,  41327,    538,\n",
       "            4024,    389,    264,   2115,   8577,    311,    279,  42014,     11,\n",
       "             323,    872,    538,    315,    220,    605,   4236,  27092,    449,\n",
       "            2500,    538,    449,    279,   1890,   3392,    315,   4236,     13,\n",
       "             220,     20,   6699,   9076,    311,    387,    264,    523,   3271,\n",
       "             606,     11,    323,    220,     17,    315,    279,  13639,    505,\n",
       "            2225,   6989,    690,    387,   1070,   2288,     13,   3277,    279,\n",
       "            2978,   1938,    574,    927,     11,    279,   4236,   1436,   5268,\n",
       "             311,    733,   2162,    323,    220,    605,    315,   1124,   2163,\n",
       "              13,   9220,    315,    279,    523,   3271,   3233,   1051,   6699,\n",
       "             304,    430,   1912,     11,    779,    814,   2163,    439,   1664,\n",
       "              13,   2650,   1690,   7931,   1051,   2163,    520,    279,  42014,\n",
       "            4710,  22103,     25],\n",
       "         [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,  15383,    596,  11326,  12893,\n",
       "             220,     16,   6596,    315,   5403,   2391,    279,   9178,     13,\n",
       "            1952,   6740,   3814,     11,  15383,   1373,    369,    220,    845,\n",
       "            4520,     13,   1952,   7884,   1364,   1373,    369,    220,   1591,\n",
       "            4520,     13,   2650,   1690,   4520,   1587,  15383,    617,    311,\n",
       "            1373,    389,   7418,    311,   4686,    279,  16720,   4710,  22103,\n",
       "              25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004],\n",
       "         [128000,     32,  10652,   1990,   2724,    323,  22103,     13,    578,\n",
       "            1217,  17501,    264,   3488,     11,    323,    279,  22103,  68577,\n",
       "             433,     13,    578,  18328,   1176,  15849,    922,    279,  33811,\n",
       "            1920,    304,    279,   4059,    323,   1243,   5825,    279,   1217,\n",
       "             449,    279,   4320,     13,    578,  33811,   1920,    323,   4320,\n",
       "             527,  44910,   2949,    366,  27963,   1500,  27963,     29,    323,\n",
       "             366,   9399,   1500,   9399,     29,   9681,     11,  15947,     11,\n",
       "             602,   1770,   2637,    366,  27963,     29,  20489,    287,   1920,\n",
       "            1618,    524,  27963,     29,    366,   9399,     29,   9399,   1618,\n",
       "             524,   9399,  14611,   2724,     25,    578,  31230,    315,    264,\n",
       "            5410,  19794,  79771,    374,    220,    605,   7693,   3485,    279,\n",
       "            5015,     13,    220,  23212,     11,   1455,  11909,    690,   2019,\n",
       "             430,    264,   2851,   2011,    387,   3025,    311,   5662,    520,\n",
       "            3325,    220,     21,  15271,   3485,    279,  31230,    311,  64572,\n",
       "             264,  19794,     13,    220,  83710,    264,  19794,   2851,    374,\n",
       "             220,     21,   7693,  16615,    323,    649,   5662,    220,   1313,\n",
       "           15271,   3485,    872,   2010,   1701,    279,  27296,    857,    315,\n",
       "             872,  11977,     13,    220,   2650,   1579,   2011,    420,   2851,\n",
       "             387,   3025,    311,   7940,    311,   5662,    220,     21,  15271,\n",
       "            3485,    279,  31230,    311,  64572,    264,  19794,   4710,  22103,\n",
       "              25, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "          128004, 128004, 128004]]),\n",
       " 'answers': ['7', '15', '16', '32']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Next TODO:\n",
    "- [ ] Properly format the prompt in the data\n",
    "- [ ] Do the RL training loop"
   ],
   "id": "872551481417c09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "RESEARCH IDEA:\n",
    "Continuous RL for CoT? instead of predicting tokens, we predict the continuous embeddings"
   ],
   "id": "46fa9d9db0976173"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
